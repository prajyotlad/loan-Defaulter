{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\Prajyot Lad\\Python\\XYZCorp_LendingData.txt\",delimiter=\"\\t\")\n",
    "df_rev=pd.DataFrame.copy(df)\n",
    "df_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev=df_rev.drop([\"mths_since_last_record\",\"mths_since_last_major_derog\",\"annual_inc_joint\",\n",
    "            \"dti_joint\",\"verification_status_joint\",\"open_acc_6m\",\"open_il_6m\",\n",
    "            \"open_il_12m\",\"open_il_24m\",\"mths_since_rcnt_il\",\"total_bal_il\",\n",
    "            \"il_util\",\"open_rv_12m\",\"open_rv_24m\",\"max_bal_bc\",\"all_util\",\n",
    "            \"total_rev_hi_lim\",\"inq_fi\",\"total_cu_tl\",\"inq_last_12m\",\n",
    "            \"mths_since_last_delinq\",\"id\",\"member_id\",\"emp_title\",\"purpose\",\n",
    "            \"title\",\"zip_code\",\"addr_state\",\"desc\",\"emp_length\",\"last_pymnt_d\",\n",
    "            \"last_credit_pull_d\",\"next_pymnt_d\",\"pymnt_plan\",\n",
    "            \"grade\",\"sub_grade\",\"earliest_cr_line\",\"total_acc\"],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing values\n",
    "df_rev.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treatment of Missing Values\n",
    "for value in[\"revol_util\",\"collections_12_mths_ex_med\",\"tot_coll_amt\",\"tot_cur_bal\"]:\n",
    "    df_rev[value].fillna(df_rev[value].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#issue_d is object datatype to make use for split issue_d in date\n",
    "df_rev.issue_d=pd.to_datetime(df_rev.issue_d) \n",
    "col_name='issue_d'\n",
    "print(df_rev[col_name].dtype)\n",
    "df_rev.issue_d\n",
    "df_rev.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical variable to numeric\n",
    "colname=[]\n",
    "for x in df_rev.columns:\n",
    "    if df_rev[x].dtype==\"object\":\n",
    "        colname.append(x)\n",
    "colname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For preprocessing the data\n",
    "from sklearn import preprocessing\n",
    "le=preprocessing.LabelEncoder()\n",
    "for x in colname:\n",
    "    df_rev[x]=le.fit_transform(df_rev[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data in test and train*\n",
    "split_date=\"Jun-2015\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training=df_rev.loc[df_rev['issue_d']< split_date]\n",
    "df_training=df_training.drop(['issue_d'],axis=1)\n",
    "df_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_rev.loc[df_rev['issue_d']>= split_date]\n",
    "df_test=df_test.drop(['issue_d'],axis=1)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting X and Y\n",
    "X_train=df_training.values[:,:-1]\n",
    "Y_train=df_training.values[:,-1]\n",
    "Y_train=Y_train.astype(int)\n",
    "print(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=df_test.values[:,:-1]\n",
    "Y_test=df_test.values[:,-1]\n",
    "Y_test=Y_test.astype(int)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev=df_rev.drop([\"issue_d\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "print(X_test)\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1]LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#create a model building\n",
    "classifier=LogisticRegression()\n",
    "#fitting training data to model \n",
    "classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=classifier.predict(X_test)\n",
    "print(list(zip(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier.coef_)\n",
    "print(classifier.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,\\\n",
    "classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accuracy of the model:\",acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the predicted values\n",
    "y_pred_prob=classifier.predict_proba(X_test)\n",
    "print(y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For adjusting threshold \n",
    "for a in np.arange(0.4,0.61,0.01):\n",
    "    predict_mine = np.where(y_pred_prob[:,1] > a, 1, 0)\n",
    "    cfm=confusion_matrix(Y_test, predict_mine)\n",
    "    total_err=cfm[0,1]+cfm[1,0]\n",
    "    print(\"Errors at threshold \", a, \":\",total_err, \" , type 2 error :\",\n",
    "    cfm[1,0],\" , type 1 error:\", cfm[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class=[]\n",
    "for value in y_pred_prob[:,1]:\n",
    "    if value > 0.45:\n",
    "        y_pred_class.append(1)\n",
    "    else:\n",
    "        \n",
    "        y_pred_class.append(0)\n",
    "print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat confusion matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,\\\n",
    "classification_report\n",
    "cfm=confusion_matrix(Y_test,y_pred_class)\n",
    "print(cfm)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,y_pred_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(Y_test,y_pred_class)\n",
    "print(\"Accuracy of the model:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC\n",
    "from sklearn import metrics\n",
    "fpr, tpr, z = metrics.roc_curve(Y_test, y_pred_prob[:,1])\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = auc)\n",
    "plt.legend(loc = 'lower right')        \n",
    "plt.plot([0, 1], [0, 1],'r--')  #redline\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note-Adjusting threshold dosent help.\n",
    "#before Adj thresh recall value for 1= 0.51,after adj thresh = 0.52(0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2]Decision Tree\n",
    "#Model Building(Decision Tree)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_DT=DecisionTreeClassifier(criterion=\"gini\",random_state=10)\n",
    "model_DT.fit(X_train,Y_train)\n",
    "Y_pred=model_DT.predict(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature imp\n",
    "print(list(zip(df_rev.columns,model_DT.feature_importances_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate file and upload the code in webgraphviz.com to plot the decision tree\n",
    "#from sklearn import tree\n",
    "#with open('/Users/Prajyot/Desktop/model_DT.txt','w') as f:\n",
    "#    f=tree.export_graphviz(model_DT,feature_names=df_rev[:-1],out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3]SVM\n",
    "from sklearn import svm\n",
    "model_DT=svm.SVC(kernel=\"rbf\",gamma=0.1,C=50)\n",
    "model_DT.fit(X_train,Y_train)\n",
    "Y_pred=model_DT.predict(X_test)\n",
    "print(Y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble Modelling\n",
    "#4]Bagging\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model=ExtraTreesClassifier(n_estimators=151,random_state=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5]Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier(n_estimators=101,random_state=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6]AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model_AdaBoost=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=50,random_state=10)\n",
    "model_AdaBoost.fit(X_train,Y_train)\n",
    "Y_pred=model_AdaBoost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7]GradientBoost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model_GradientBoosting=GradientBoostingClassifier(n_estimators=71,random_state=10)\n",
    "model_GradientBoosting.fit(X_train,Y_train)\n",
    "Y_pred=model_GradientBoosting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8]Ensemble Model(Voting Classifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('log', model1))\n",
    "model2 = DecisionTreeClassifier(criterion='gini',random_state=10)\n",
    "estimators.append(('cart', model2))\n",
    "# = SVC(kernel=\"rbf\", C=70,gamma=0.1)\n",
    "#estimators.append(('svm', model3))\n",
    "#model4 = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "#estimators.append(('knn', model4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "ensemble.fit(X_train,Y_train)\n",
    "Y_pred=ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
